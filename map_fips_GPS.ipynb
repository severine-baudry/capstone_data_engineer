{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping of covid locations (fips + GPS) to the closest weather station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "from pyspark.sql.types import MapType, StringType, FloatType\n",
    "from pyspark.sql import DataFrame\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"capstone.cfg\")\n",
    "\n",
    "os.chdir(config[\"PATH\"][\"project\"])\n",
    "project_path = config[\"PATH\"][\"project\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"covid_DB\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relevant stations with weather element\n",
    "path = os.path.join(project_path, \"OUT_DATA\", \"filtered_stations\")\n",
    "selected_stations = spark.read.parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- measured: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_stations.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|measured|\n",
      "+--------+\n",
      "|    TMIN|\n",
      "|    SNOW|\n",
      "|    AWND|\n",
      "|    PRCP|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_stations.select(\"measured\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all stations, with GPS location\n",
    "raw_stations = spark.read.csv( os.path.join(project_path, \"DATA\", \"WEATHER\", \"ghcnd-stations.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse raw stations into columns\n",
    "@udf(MapType( StringType(), StringType()))\n",
    "def ParseStationsUDF(line):\n",
    "    return{\n",
    "        \"station_id\": line[0:11],\n",
    "        \"latitude\" : line[13:20], \n",
    "        \"longitude\" : line[21:30], \n",
    "        \"elevation\" : line[31:38], \n",
    "        \"state\" : line[38:40], \n",
    "        \"station_name\" : line[41:]\n",
    "        \n",
    "    }\n",
    "\n",
    "fields = OrderedDict( [\n",
    "        ( \"station_id\" , \"string\"),\n",
    "        ( \"latitude\" , \"float\"), \n",
    "        (\"longitude\" , \"float\"), \n",
    "        (\"elevation\" , \"float\"),\n",
    "        (\"state\" , \"string\"), \n",
    "        (\"station_name\" , \"string\")\n",
    "] )\n",
    "\n",
    "#exprs = [ f\"parsed['{field}'].cast({fld_type}) as {field}\" for field, fld_type in fields.items() ]\n",
    "exprs = [ f\"CAST(parsed['{field}'] AS {fld_type}) AS {field}\" for field, fld_type in fields.items() ]\n",
    "\n",
    "df_stations = raw_stations.withColumn(\"parsed\", ParseStationsUDF(\"_c0\")).selectExpr( *exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- elevation: float (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- station_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stations.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = df_stations.join(selected_stations, [\"station_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23556"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stations.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- elevation: float (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- station_name: string (nullable = true)\n",
      " |-- measured: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stations.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------+---------+-----+--------------------+--------+\n",
      "| station_id|latitude|longitude|elevation|state|        station_name|measured|\n",
      "+-----------+--------+---------+---------+-----+--------------------+--------+\n",
      "|AQC00914000| 14.3167|-170.7667|    408.4|   AS|AASUFOU          ...|    PRCP|\n",
      "|AQC00914141| 14.2667|-170.6167|      4.6|   AS|FAGAITUA         ...|    PRCP|\n",
      "|AQC00914594| 14.3333|-170.7667|     42.4|   AS|MALAELOA         ...|    PRCP|\n",
      "|AQW00061705| 14.3306|-170.7136|      3.7|   AS|PAGO PAGO WSO AP ...|    AWND|\n",
      "|AQW00061705| 14.3306|-170.7136|      3.7|   AS|PAGO PAGO WSO AP ...|    TMIN|\n",
      "|AQW00061705| 14.3306|-170.7136|      3.7|   AS|PAGO PAGO WSO AP ...|    PRCP|\n",
      "|CQC00914080| 15.2136| 145.7497|    252.1|   MP|CAPITOL HILL 1   ...|    TMIN|\n",
      "|CQC00914080| 15.2136| 145.7497|    252.1|   MP|CAPITOL HILL 1   ...|    PRCP|\n",
      "|CQC00914801| 14.1717| 145.2428|    179.2|   MP|ROTA AP          ...|    TMIN|\n",
      "|CQC00914801| 14.1717| 145.2428|    179.2|   MP|ROTA AP          ...|    PRCP|\n",
      "+-----------+--------+---------+---------+-----+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stations.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NYT locations (FIPS + GPS)\n",
    "path = os.path.join(project_path, \"OUT_DATA\", \"nyt_locations_geography\")\n",
    "df_locations = spark.read.parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations = df_locations.where( ( ~ F.isnan(\"latitude\") ) | (~ F.isnan(\"longitude\")) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fips: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_locations.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_distance(l_ref : DataFrame) -> DataFrame:\n",
    "    l_ref = l_ref.withColumnRenamed(\"latitude\", \"latitude_degrees\")\n",
    "    l_ref = l_ref.withColumnRenamed( \"longitude\", \"longitude_degrees\") \n",
    "    @udf( FloatType())\n",
    "    def degree_to_radian(x):\n",
    "        return  x* np.pi / 180.\n",
    "    l_ref = l_ref.withColumn(\"latitude\", degree_to_radian(\"latitude_degrees\") )\n",
    "    l_ref = l_ref.withColumn(\"longitude\", degree_to_radian(\"longitude_degrees\") )\n",
    "    l_ref = l_ref.withColumn(\"cos_latitude\", F.cos(\"latitude\") )  \n",
    "    print(type(l_ref))\n",
    "    return l_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_ref(l_ref, lati, longi):\n",
    "        ''' computation of angular distance between 2 locations given by GPS coordinates\n",
    "        exact formulas (maybe overkill), taken from :\n",
    "        https://www.movable-type.co.uk/scripts/latlong.html\n",
    "        '''    \n",
    "        latitude = float(lati) * np.pi / 180.\n",
    "        longitude = float(longi) * np.pi / 180.\n",
    "        cos_lat = np.cos(latitude)\n",
    "        #print( f'latitude : {latitude}, longitude : {longitude}, cos(latitude) : {cos_lat}')\n",
    "        # Haversine formula\n",
    "        l_ref[\"delta_lat_term\"] = ( np.sin( (l_ref[\"latitude\"] - latitude) * 0.5 ) )**2\n",
    "        l_ref[\"delta_long_term\"] = ( np.sin( (l_ref[\"longitude\"] - longitude) * 0.5) )**2\n",
    "        l_ref[\"a\"] = l_ref[\"delta_lat_term\"] + l_ref[\"delta_long_term\"] \\\n",
    "                        * cos_lat * l_ref[\"cos_latitude\"]\n",
    "        l_ref[\"sqrt_a\"] = l_ref[\"a\"].apply( lambda x : np.sqrt(x) )\n",
    "        l_ref[\"sqrt_1_a\"] = l_ref[\"a\"].apply(lambda x : np.sqrt(1.- x) )\n",
    "        l_ref[\"angle\"] = np.arctan2( np.sqrt(l_ref[\"a\"]), np.sqrt( 1. - l_ref[\"a\"] ) )\n",
    "        closest = l_ref[\"angle\"].idxmin()\n",
    "        #print(closest)\n",
    "        return closest, l_ref.iloc[closest]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_stations_precompute =precompute_distance(df_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23556"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stations_precompute.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- latitude_degrees: float (nullable = true)\n",
      " |-- longitude_degrees: float (nullable = true)\n",
      " |-- elevation: float (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- station_name: string (nullable = true)\n",
      " |-- measured: string (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- cos_latitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stations_precompute.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(min(longitude_degrees)=-170.76669311523438, min(latitude_degrees)=13.389399528503418, min(latitude)=0.2336890995502472, min(longitude)=-2.980441093444824)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stations_precompute.agg({\"latitude\" : \"min\", \"longitude\" : \"min\", \"latitude_degrees\" : \"min\", \"longitude_degrees\" : \"min\" } ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(longitude_degrees)=145.74969482421875, max(latitude_degrees)=71.32140350341797, max(latitude)=1.2447932958602905, max(longitude)=2.5438120365142822)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stations_precompute.agg({\"latitude\" : \"max\", \"longitude\" : \"max\", \"latitude_degrees\" : \"max\", \"longitude_degrees\" : \"max\" } ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_locations_precompute = precompute_distance(df_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(min(longitude_degrees)=-164.1889190673828, min(latitude_degrees)=13.444, min(latitude)=0.23464205861091614, min(longitude)=-2.8656373023986816)]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_locations_precompute.agg({\"latitude\" : \"min\", \"longitude\" : \"min\", \"latitude_degrees\" : \"min\", \"longitude_degrees\" : \"min\" } ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(longitude_degrees)=178.33880615234375, max(latitude_degrees)=69.4493408203125, max(latitude)=1.212119698524475, max(longitude)=3.1125993728637695)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_locations_precompute.agg({\"latitude\" : \"max\", \"longitude\" : \"max\", \"latitude_degrees\" : \"max\", \"longitude_degrees\" : \"max\" } ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------------+-------------------+------+\n",
      "| fips|              county|          latitude|          longitude| state|\n",
      "+-----+--------------------+------------------+-------------------+------+\n",
      "|02998|Yakutat plus Hoon...|               NaN|                NaN|Alaska|\n",
      "|02997|Bristol Bay plus ...|               NaN|                NaN|Alaska|\n",
      "|02185| North Slope Borough|  69.4493408203125| -153.4728240966797|Alaska|\n",
      "|02188|Northwest Arctic ...| 67.00506591796875|-160.02108764648438|Alaska|\n",
      "| null|             Unknown|         66.160507|-153.36914099999998|Alaska|\n",
      "|02290|Yukon-Koyukuk Cen...| 65.37572479248047|-151.57785034179688|Alaska|\n",
      "|02180|    Nome Census Area| 64.78368377685547| -164.1889190673828|Alaska|\n",
      "|02090|Fairbanks North S...| 64.67604064941406|-146.54815673828125|Alaska|\n",
      "|02240|Southeast Fairban...| 63.86499786376953| -143.2186279296875|Alaska|\n",
      "|02068|      Denali Borough|63.682037353515625| -150.0270233154297|Alaska|\n",
      "+-----+--------------------+------------------+-------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_locations.sort(\"latitude\", ascending = False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fips: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_locations.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------+---------+------+\n",
      "| fips|              county|latitude|longitude| state|\n",
      "+-----+--------------------+--------+---------+------+\n",
      "|02997|Bristol Bay plus ...|     NaN|      NaN|Alaska|\n",
      "|02998|Yakutat plus Hoon...|     NaN|      NaN|Alaska|\n",
      "+-----+--------------------+--------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_locations.where(col(\"latitude\") == \"NaN\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations = df_locations.replace(\"NaN\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------------+-------------------+------+\n",
      "| fips|              county|          latitude|          longitude| state|\n",
      "+-----+--------------------+------------------+-------------------+------+\n",
      "|02998|Yakutat plus Hoon...|               NaN|                NaN|Alaska|\n",
      "|02997|Bristol Bay plus ...|               NaN|                NaN|Alaska|\n",
      "|02185| North Slope Borough|  69.4493408203125| -153.4728240966797|Alaska|\n",
      "|02188|Northwest Arctic ...| 67.00506591796875|-160.02108764648438|Alaska|\n",
      "| null|             Unknown|         66.160507|-153.36914099999998|Alaska|\n",
      "|02290|Yukon-Koyukuk Cen...| 65.37572479248047|-151.57785034179688|Alaska|\n",
      "|02180|    Nome Census Area| 64.78368377685547| -164.1889190673828|Alaska|\n",
      "|02090|Fairbanks North S...| 64.67604064941406|-146.54815673828125|Alaska|\n",
      "|02240|Southeast Fairban...| 63.86499786376953| -143.2186279296875|Alaska|\n",
      "|02068|      Denali Borough|63.682037353515625| -150.0270233154297|Alaska|\n",
      "+-----+--------------------+------------------+-------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_locations.sort(\"latitude\", ascending = False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
