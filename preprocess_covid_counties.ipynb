{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "from pyspark.sql.types import MapType, StringType, FloatType\n",
    "from pyspark.sql import DataFrame, Window\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"capstone.cfg\")\n",
    "\n",
    "local_data_dir = config[\"PATH\"][\"LOCAL_DATA_DIR\"]\n",
    "output_path =  config[\"PATH\"][\"STAGE_DATA_DIR\"]\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"covid_DB\") \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "        .config(\"fs.s3a.access.key\", config['AWS']['ACCESS_KEY_ID'])\\\n",
    "        .config(\"fs.s3a.secret.key\", config['AWS']['SECRET_ACCESS_KEY'])\\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .csv(os.path.join(local_data_dir,\"COVID\", \"us-counties.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- fips: string (nullable = true)\n",
      " |-- cases: string (nullable = true)\n",
      " |-- deaths: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_covid.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = df_covid.withColumn(\"date\", F.to_date(\"date\"))\n",
    "df_covid = df_covid.withColumn(\"cases\", col(\"cases\").cast(T.IntegerType()) )\n",
    "df_covid = df_covid.withColumn(\"deaths\", col(\"deaths\").cast(T.IntegerType()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- fips: string (nullable = true)\n",
      " |-- cases: integer (nullable = true)\n",
      " |-- deaths: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_covid.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+-----+-----+------+\n",
      "|      date|     county|     state| fips|cases|deaths|\n",
      "+----------+-----------+----------+-----+-----+------+\n",
      "|2020-01-21|  Snohomish|Washington|53061|    1|     0|\n",
      "|2020-01-22|  Snohomish|Washington|53061|    1|     0|\n",
      "|2020-01-23|  Snohomish|Washington|53061|    1|     0|\n",
      "|2020-01-24|       Cook|  Illinois|17031|    1|     0|\n",
      "|2020-01-24|  Snohomish|Washington|53061|    1|     0|\n",
      "|2020-01-25|     Orange|California|06059|    1|     0|\n",
      "|2020-01-25|       Cook|  Illinois|17031|    1|     0|\n",
      "|2020-01-25|  Snohomish|Washington|53061|    1|     0|\n",
      "|2020-01-26|   Maricopa|   Arizona|04013|    1|     0|\n",
      "|2020-01-26|Los Angeles|California|06037|    1|     0|\n",
      "|2020-01-26|     Orange|California|06059|    1|     0|\n",
      "|2020-01-26|       Cook|  Illinois|17031|    1|     0|\n",
      "|2020-01-26|  Snohomish|Washington|53061|    1|     0|\n",
      "|2020-01-27|   Maricopa|   Arizona|04013|    1|     0|\n",
      "|2020-01-27|Los Angeles|California|06037|    1|     0|\n",
      "|2020-01-27|     Orange|California|06059|    1|     0|\n",
      "|2020-01-27|       Cook|  Illinois|17031|    1|     0|\n",
      "|2020-01-27|  Snohomish|Washington|53061|    1|     0|\n",
      "|2020-01-28|   Maricopa|   Arizona|04013|    1|     0|\n",
      "|2020-01-28|Los Angeles|California|06037|    1|     0|\n",
      "+----------+-----------+----------+-----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_covid.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1170376"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10721"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid.where(col(\"fips\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_fips_stations = spark.read.parquet( os.path.join(output_path, \"map_locations_stations\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- location_id: long (nullable = true)\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      " |-- measured: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "map_fips_stations.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fips: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- location_id: long (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fpath = os.path.join(output_path, \"nyt_locations_geography\")\n",
    "nyt_locations = spark.read.parquet(fpath)\n",
    "nyt_locations.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+\n",
      "|              county| state| fips|\n",
      "+--------------------+------+-----+\n",
      "|Yakutat plus Hoon...|Alaska|02998|\n",
      "|Bristol Bay plus ...|Alaska|02997|\n",
      "+--------------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show non matched locations \n",
    "df_covid.join(nyt_locations, \n",
    "            (df_covid.fips.eqNullSafe(nyt_locations.fips) ) &\n",
    "            (df_covid.county.eqNullSafe(nyt_locations.county) )& \n",
    "            (df_covid.state.eqNullSafe( nyt_locations.state) ) ,\n",
    "            how = \"left_anti\")\\\n",
    "            .select(\"county\", \"state\", \"fips\")\\\n",
    "            .distinct()\\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out non matched locations and add location_id\n",
    "df_covid_filter = df_covid.alias(\"covid\").join( nyt_locations.alias(\"loc\"),\n",
    "            (df_covid.fips.eqNullSafe(nyt_locations.fips) ) &\n",
    "            (df_covid.county.eqNullSafe(nyt_locations.county) ) & \n",
    "            (df_covid.state.eqNullSafe( nyt_locations.state) ) )\\\n",
    "       .select(\"date\", \"location_id\", \"covid.fips\", \"covid.county\", \"covid.state\", \"deaths\", \"cases\")\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute daily cases and daily deaths, from cumulated values\n",
    "# first add a column with the lag value (i.e. the value from the previous day)\n",
    "# then compute the difference btw current day and previous day values\n",
    "w = Window.partitionBy(\"location_id\").orderBy(\"date\")\n",
    "df_covid_daily = df_covid_filter\\\n",
    "    .withColumn(\"deaths_prev\", F.lag(\"deaths\", count = 1, default = 0).over(w) ) \\\n",
    "    .withColumn(\"cases_prev\", F.lag(\"cases\", count = 1, default = 0).over(w) )\\\n",
    "    .withColumn(\"daily_deaths\", col(\"deaths\") - col(\"deaths_prev\"))\\\n",
    "    .withColumn(\"daily_cases\", col(\"cases\") - col(\"cases_prev\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- location_id: long (nullable = true)\n",
      " |-- fips: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- deaths: integer (nullable = true)\n",
      " |-- cases: integer (nullable = true)\n",
      " |-- deaths_prev: integer (nullable = true)\n",
      " |-- cases_prev: integer (nullable = true)\n",
      " |-- daily_deaths: integer (nullable = true)\n",
      " |-- daily_cases: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_covid_daily.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(output_path, \"covid_per_county\")\n",
    "\n",
    "df_covid_daily.select(\"date\", \"location_id\", \"daily_cases\", \"daily_deaths\")\\\n",
    "    .write\\\n",
    "    .partitionBy(\"date\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .parquet(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = df_covid_daily.agg({\"date\" : \"max\" }).collect()[0][\"max(date)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 3, 29)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute last date for each location_id : used to filter out data for subsequent loads\n",
    "w = Window.partitionBy(\"location_id\").orderBy( col(\"date\").desc())\n",
    "columns = df_covid_filter.columns[:]\n",
    "last_data = df_covid_filter.withColumn(\"rank\", F.rank().over(w))\\\n",
    "    .where(\"rank == 1\")\\\n",
    "    .select(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(output_path, \"last_data\")\n",
    "last_data.write\\\n",
    "    .format(\"parquet\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .parquet(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3272"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- location_id: long (nullable = true)\n",
      " |-- fips: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- deaths: integer (nullable = true)\n",
      " |-- cases: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "last_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
