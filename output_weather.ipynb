{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter weather stations and weather data according to selected elements and station_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession, Window\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "from pyspark.sql.types import MapType, StringType\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['capstone.cfg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"capstone.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(config[\"PATH\"][\"project\"])\n",
    "project_path = config[\"PATH\"][\"project\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"covid_DB\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(project_path, \"DATA\", \"WEATHER\", \"2020.csv.gz\")\n",
    "weather = spark.read.csv(path,  \n",
    "                         schema = \"station_id string, date string, measured string, value string, measurement_flag string, quality_flag string, source_flag string, hour string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mapping btw locations and stations\n",
    "path = os.path.join(project_path, \"OUT_DATA\", \"map_locations_stations\")\n",
    "map_locations_to_stations = spark.read.parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all stations, with GPS location\n",
    "raw_stations = spark.read.csv( os.path.join(project_path, \"DATA\", \"WEATHER\", \"ghcnd-stations.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse raw stations into columns\n",
    "@udf(MapType( StringType(), StringType()))\n",
    "def ParseStationsUDF(line):\n",
    "    return{\n",
    "        \"station_id\": line[0:11],\n",
    "        \"latitude\" : line[13:20], \n",
    "        \"longitude\" : line[21:30], \n",
    "        \"elevation\" : line[31:38], \n",
    "        \"state\" : line[38:40], \n",
    "        \"station_name\" : line[41:]\n",
    "        \n",
    "    }\n",
    "\n",
    "fields = OrderedDict( [\n",
    "        ( \"station_id\" , \"string\"),\n",
    "        ( \"latitude\" , \"float\"), \n",
    "        (\"longitude\" , \"float\"), \n",
    "        (\"elevation\" , \"float\"),\n",
    "        (\"state\" , \"string\"), \n",
    "        (\"station_name\" , \"string\")\n",
    "] )\n",
    "\n",
    "#exprs = [ f\"parsed['{field}'].cast({fld_type}) as {field}\" for field, fld_type in fields.items() ]\n",
    "exprs = [ f\"CAST(parsed['{field}'] AS {fld_type}) AS {field}\" for field, fld_type in fields.items() ]\n",
    "\n",
    "stations = raw_stations.withColumn(\"parsed\", ParseStationsUDF(\"_c0\")).selectExpr( *exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['station_id', 'latitude', 'longitude', 'elevation', 'state', 'station_name']\n"
     ]
    }
   ],
   "source": [
    "col_stations = stations.columns\n",
    "print(col_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only selected weather data\n",
    "selected_stations = stations.join(map_locations_to_stations, on = [\"station_id\"])\\\n",
    "    .select(*col_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(project_path, \"OUT_DATA\", \"weather_stations\")\n",
    "selected_stations.write.parquet(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_weather = weather.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_weather = weather.filter(weather[\"quality_flag\"].isNull())\\\n",
    "    .join( map_locations_to_stations, on = [\"station_id\", \"measured\"])\\\n",
    "    .select(\"measured\", \"station_id\", \"date\", \"value\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(project_path, \"OUT_DATA\", \"weather_data\")\n",
    "selected_weather.write.parquet(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
