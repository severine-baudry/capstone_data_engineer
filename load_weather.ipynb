{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import MapType, StringType\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta\n",
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "from urllib.error import *\n",
    "from urllib.parse import urljoin\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['capstone.cfg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"capstone.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(config[\"PATH\"][\"project\"])\n",
    "project_path = config[\"PATH\"][\"project\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create spark session. Add driver postgress to enable to load from existing postgres DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add driver postgress to enable to load from existing postgres DB\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"US_weather\") \\\n",
    "    .config(\"spark.jars\", \"postgresql-42.2.18.jar\")\\\n",
    "    .config( \"spark.driver.extraClassPath\", \"postgresql-42.2.18.jar\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dir = \"https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/2020.csv.gz\n"
     ]
    }
   ],
   "source": [
    "weather_2020 = \"2020.csv.gz\"\n",
    "url_weather = urljoin( urljoin(weather_dir,\"by_year\"), weather_2020)\n",
    "print(url_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/user/CODE/BIG_DATA/CAPSTONE_PROJECT/covid-analysis/DATA/WEATHER/2020.csv.gz',\n",
       " <http.client.HTTPMessage at 0x7ff5bfff1ad0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_weather = os.path.join(project_path, \"DATA\", \"WEATHER\", weather_2020)\n",
    "urllib.request.urlretrieve(url_weather, out_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weather_file in [\"ghcnd-stations.txt\", \"ghcnd-states.txt\", \"ghcnd-countries.txt\", \"readme.txt\"]:\n",
    "    url = urljoin(weather_dir, weather_file)\n",
    "    out = os.path.join(project_path, \"DATA\", \"WEATHER\", weather_file)\n",
    "    urllib.request.urlretrieve(url, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Covid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/nytimes/covid-19-data/raw/master/us-counties.csv\n",
      "/home/user/CODE/BIG_DATA/CAPSTONE_PROJECT/covid-analysis/DATA/COVID/us-counties.csv\n"
     ]
    }
   ],
   "source": [
    "nyt_dir = \"https://github.com/nytimes/covid-19-data/raw/master/\"\n",
    "nyt_covid  = \"us-counties.csv\"\n",
    "url = urljoin(nyt_dir, nyt_covid)\n",
    "out = os.path.join(project_path, \"DATA\", \"COVID\", nyt_covid)\n",
    "print(url)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/user/CODE/BIG_DATA/CAPSTONE_PROJECT/covid-analysis/DATA/COVID/us-counties.csv',\n",
       " <http.client.HTTPMessage at 0x7f3a92752610>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(url, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download counties geographic information\n",
    "Covid-19 statistics are provided by FIPS county codes; weather information are available by geographic coordinates (latitude and longitude). Thus, to join weather data with Covid-19 information, we need to get geographic coordinates of county FIPS first. Gazetteer information provided by the US Census Bureau provide such information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/user/CODE/BIG_DATA/CAPSTONE_PROJECT/covid-analysis/DATA/2020_Gaz_counties_national.zip',\n",
       " <http.client.HTTPMessage at 0x7f9e32a05690>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gazetteer_dir = \"https://www2.census.gov/geo/docs/maps-data/data/gazetteer/2020_Gazetteer/\"\n",
    "gazetteer_name =\"2020_Gaz_counties_national.zip\"\n",
    "url = urljoin(gazetteer_dir, gazetteer_name)\n",
    "out = os.path.join(project_path, \"DATA\", gazetteer_name)\n",
    "urllib.request.urlretrieve(url, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  DATA/2020_Gaz_counties_national.zip\r\n",
      "  inflating: 2020_Gaz_counties_national.txt  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip DATA/2020_Gaz_counties_national.zip\n",
    "! tail -n +2 2020_Gaz_counties_national.txt > DATA/2020_Gaz_counties_national.txt\n",
    "! rm 2020_Gaz_counties_national.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Covid-19 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_daily_perfips = spark.read.csv( os.path.join(project_path, \"DATA\", \"COVID\",nyt_covid), header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- fips: string (nullable = true)\n",
      " |-- cases: string (nullable = true)\n",
      " |-- deaths: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "covid_daily_perfips.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+-----+-----+------+\n",
      "|      date|     county|     state| fips|cases|deaths|\n",
      "+----------+-----------+----------+-----+-----+------+\n",
      "|2020-01-21|  Snohomish|Washington|53061|    1|     0|\n",
      "|2020-01-22|  Snohomish|Washington|53061|    1|     0|\n",
      "|2020-01-23|  Snohomish|Washington|53061|    1|     0|\n",
      "|2020-01-24|       Cook|  Illinois|17031|    1|     0|\n",
      "|2020-01-24|  Snohomish|Washington|53061|    1|     0|\n",
      "|2020-01-25|     Orange|California|06059|    1|     0|\n",
      "|2020-01-25|       Cook|  Illinois|17031|    1|     0|\n",
      "|2020-01-25|  Snohomish|Washington|53061|    1|     0|\n",
      "|2020-01-26|   Maricopa|   Arizona|04013|    1|     0|\n",
      "|2020-01-26|Los Angeles|California|06037|    1|     0|\n",
      "+----------+-----------+----------+-----+-----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "covid_daily_perfips.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load counties geographic information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(MapType( StringType(), StringType()))\n",
    "def ParseGazetteerUDF(line):\n",
    "    l_str = line.split()\n",
    "    l = len(l_str)\n",
    "    l_headers = 10\n",
    "    n_words = l - l_headers + 1\n",
    "    county = \" \".join( l_str[3:3+n_words] )\n",
    "\n",
    "    return{\n",
    "        \"state\": l_str[0],\n",
    "        \"county\" : county ,        \n",
    "        \"fips\" : l_str[1], \n",
    "        \"latitude\" : l_str[-2], \n",
    "        \"longitude\" : l_str[-1] \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"CAST(parsed['state'] AS string) AS state\",\n",
       " \"CAST(parsed['county'] AS string) AS county\",\n",
       " \"CAST(parsed['fips'] AS int) AS fips\",\n",
       " \"CAST(parsed['latitude'] AS float) AS latitude\",\n",
       " \"CAST(parsed['longitude'] AS float) AS longitude\"]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = OrderedDict( [\n",
    "        ( \"state\" , \"string\"),\n",
    "        (\"county\" , \"string\"),\n",
    "        (\"fips\" , \"int\"),\n",
    "        ( \"latitude\" , \"float\"), \n",
    "        (\"longitude\" , \"float\") \n",
    "] )\n",
    "\n",
    "exprs = [ f\"CAST(parsed['{field}'] AS {fld_type}) AS {field}\" for field, fld_type in fields.items() ]\n",
    "exprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gazetteer = spark.read.csv(os.path.join(project_path, \"DATA\", \"2020_Gaz_counties_national.txt\"))\\\n",
    "    .withColumn(\"parsed\", ParseGazetteerUDF(\"_c0\")).selectExpr( *exprs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- fips: integer (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gazetteer.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----+---------+----------+\n",
      "|state|         county|fips| latitude| longitude|\n",
      "+-----+---------------+----+---------+----------+\n",
      "|   AL| Autauga County|1001|32.532238| -86.64644|\n",
      "|   AL| Baldwin County|1003|30.659218| -87.74606|\n",
      "|   AL| Barbour County|1005|31.870253|-85.405106|\n",
      "|   AL|    Bibb County|1007|33.015892| -87.12715|\n",
      "|   AL|  Blount County|1009| 33.97736| -86.56644|\n",
      "|   AL| Bullock County|1011| 32.10176| -85.71726|\n",
      "|   AL|  Butler County|1013|31.751667| -86.68197|\n",
      "|   AL| Calhoun County|1015|33.770515| -85.82791|\n",
      "|   AL|Chambers County|1017|32.915504|-85.394035|\n",
      "|   AL|Cherokee County|1019|34.069515| -85.65424|\n",
      "+-----+---------------+----+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gazetteer.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weather records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = spark.read.csv(out_weather,  \n",
    "                         schema = \"station_id string, date string, measured string, v1 string, v2 string, v3 string, v4 string, v5 string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- measured: string (nullable = true)\n",
      " |-- v1: string (nullable = true)\n",
      " |-- v2: string (nullable = true)\n",
      " |-- v3: string (nullable = true)\n",
      " |-- v4: string (nullable = true)\n",
      " |-- v5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+--------+---+----+----+---+----+\n",
      "| station_id|    date|measured| v1|  v2|  v3| v4|  v5|\n",
      "+-----------+--------+--------+---+----+----+---+----+\n",
      "|AE000041196|20200101|    TMIN|168|null|null|  S|null|\n",
      "|AE000041196|20200101|    PRCP|  0|   D|null|  S|null|\n",
      "|AE000041196|20200101|    TAVG|211|   H|null|  S|null|\n",
      "|AEM00041194|20200101|    PRCP|  0|null|null|  S|null|\n",
      "|AEM00041194|20200101|    TAVG|217|   H|null|  S|null|\n",
      "|AEM00041217|20200101|    TAVG|205|   H|null|  S|null|\n",
      "|AEM00041218|20200101|    TMIN|148|null|null|  S|null|\n",
      "|AEM00041218|20200101|    TAVG|199|   H|null|  S|null|\n",
      "|AFM00040938|20200101|    PRCP| 23|null|null|  S|null|\n",
      "|AFM00040938|20200101|    TAVG| 54|   H|null|  S|null|\n",
      "+-----------+--------+--------+---+----+----+---+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34571064"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weather stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = spark.read.csv( os.path.join(project_path, \"DATA\", \"WEATHER\", \"ghcnd-stations.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|ACW00011604  17.1...|\n",
      "|ACW00011647  17.1...|\n",
      "|AE000041196  25.3...|\n",
      "|AEM00041194  25.2...|\n",
      "|AEM00041217  24.4...|\n",
      "|AEM00041218  24.2...|\n",
      "|AF000040930  35.3...|\n",
      "|AFM00040938  34.2...|\n",
      "|AFM00040948  34.5...|\n",
      "|AFM00040990  31.5...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(MapType( StringType(), StringType()))\n",
    "def ParseStationsUDF(line):\n",
    "    return{\n",
    "        \"station_id\": line[0:11],\n",
    "        \"latitude\" : line[13:20], \n",
    "        \"longitude\" : line[21:30], \n",
    "        \"elevation\" : line[31:38], \n",
    "        \"state\" : line[38:40], \n",
    "        \"station_name\" : line[41:]\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"CAST(parsed['station_id'] AS string) AS station_id\",\n",
       " \"CAST(parsed['latitude'] AS float) AS latitude\",\n",
       " \"CAST(parsed['longitude'] AS float) AS longitude\",\n",
       " \"CAST(parsed['elevation'] AS float) AS elevation\",\n",
       " \"CAST(parsed['state'] AS string) AS state\",\n",
       " \"CAST(parsed['station_name'] AS string) AS station_name\"]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = OrderedDict( [\n",
    "        ( \"station_id\" , \"string\"),\n",
    "        ( \"latitude\" , \"float\"), \n",
    "        (\"longitude\" , \"float\"), \n",
    "        (\"elevation\" , \"float\"),\n",
    "        (\"state\" , \"string\"), \n",
    "        (\"station_name\" , \"string\")\n",
    "] )\n",
    "\n",
    "#exprs = [ f\"parsed['{field}'].cast({fld_type}) as {field}\" for field, fld_type in fields.items() ]\n",
    "exprs = [ f\"CAST(parsed['{field}'] AS {fld_type}) AS {field}\" for field, fld_type in fields.items() ]\n",
    "exprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_parsed = stations.withColumn(\"parsed\", ParseStationsUDF(\"_c0\")).selectExpr( *exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- elevation: float (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- station_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations_parsed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(station_id='ACW00011604', latitude=17.11669921875, longitude=-61.78329849243164, elevation=10.100000381469727, state='  ', station_name='ST JOHNS COOLIDGE FLD                       '),\n",
       " Row(station_id='ACW00011647', latitude=17.13330078125, longitude=-61.78329849243164, elevation=19.200000762939453, state='  ', station_name='ST JOHNS                                    '),\n",
       " Row(station_id='AE000041196', latitude=25.33300018310547, longitude=55.516998291015625, elevation=34.0, state='  ', station_name='SHARJAH INTER. AIRP            GSN     41196'),\n",
       " Row(station_id='AEM00041194', latitude=25.2549991607666, longitude=55.36399841308594, elevation=10.399999618530273, state='  ', station_name='DUBAI INTL                             41194'),\n",
       " Row(station_id='AEM00041217', latitude=24.433000564575195, longitude=54.6510009765625, elevation=26.799999237060547, state='  ', station_name='ABU DHABI INTL                         41217'),\n",
       " Row(station_id='AEM00041218', latitude=24.261999130249023, longitude=55.60900115966797, elevation=264.8999938964844, state='  ', station_name='AL AIN INTL                            41218'),\n",
       " Row(station_id='AF000040930', latitude=35.31700134277344, longitude=69.01699829101562, elevation=3366.0, state='  ', station_name='NORTH-SALANG                   GSN     40930'),\n",
       " Row(station_id='AFM00040938', latitude=34.209999084472656, longitude=62.22800064086914, elevation=977.2000122070312, state='  ', station_name='HERAT                                  40938'),\n",
       " Row(station_id='AFM00040948', latitude=34.566001892089844, longitude=69.21199798583984, elevation=1791.300048828125, state='  ', station_name='KABUL INTL                             40948'),\n",
       " Row(station_id='AFM00040990', latitude=31.5, longitude=65.8499984741211, elevation=1010.0, state='  ', station_name='KANDAHAR AIRPORT                       40990')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_parsed.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_parsed.select(\"STATE\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|STATE|\n",
      "+-----+\n",
      "|   AZ|\n",
      "|   SC|\n",
      "|   NS|\n",
      "|   NL|\n",
      "|   LA|\n",
      "|   MN|\n",
      "|   NJ|\n",
      "|   DC|\n",
      "|   OR|\n",
      "|   UM|\n",
      "|   NT|\n",
      "|   VA|\n",
      "|   QC|\n",
      "|   RI|\n",
      "|   KY|\n",
      "|   WY|\n",
      "|   BC|\n",
      "|   NH|\n",
      "|   MI|\n",
      "|     |\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# states are US and Canadian states\n",
    "stations_parsed.select(\"STATE\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------+---------+-----+--------------------+\n",
      "| station_id|latitude|longitude|elevation|state|        station_name|\n",
      "+-----------+--------+---------+---------+-----+--------------------+\n",
      "|CA001010066| 48.8667|-123.2833|      4.0|   BC|ACTIVE PASS      ...|\n",
      "|CA001010235|    48.4|-123.4833|     17.0|   BC|ALBERT HEAD      ...|\n",
      "|CA001010595| 48.5833|-123.5167|     85.0|   BC|BAMBERTON OCEAN C...|\n",
      "|CA001010720|    48.5|   -124.0|    351.0|   BC|BEAR CREEK       ...|\n",
      "|CA001010774|    48.5|  -123.35|     61.0|   BC|BEAVER LAKE      ...|\n",
      "|CA001010780| 48.3333|-123.6333|     12.0|   BC|BECHER BAY       ...|\n",
      "|CA001010960|    48.6|-123.4667|     38.0|   BC|BRENTWOOD BAY 2  ...|\n",
      "|CA001010961| 48.5667|  -123.45|     31.0|   BC|BRENTWOOD CLARKE ...|\n",
      "|CA001010965| 48.5667|-123.4333|     91.0|   BC|BRENTWOOD W SAANI...|\n",
      "|CA001011467| 48.5833|-123.4167|     53.0|   BC|CENTRAL SAANICH V...|\n",
      "|CA0010114F6| 48.5667|   -123.4|     38.0|   BC|CENTRAL SAANICH I...|\n",
      "|CA0010114FF|   48.55|   -123.4|     88.0|   BC|CENTRAL SAANICH T...|\n",
      "|CA001011500| 48.9333|  -123.75|     75.0|   BC|CHEMAINUS        ...|\n",
      "|CA001011743| 48.6833|   -123.6|     99.0|   BC|COBBLE HILL      ...|\n",
      "|CA001011745|   48.65|-123.5667|     61.0|   BC|COBBLE HILL DELOU...|\n",
      "|CA001011775|   48.65|   -123.4|     37.0|   BC|COLE BAY         ...|\n",
      "|CA001011810| 48.4167|-123.4833|     76.0|   BC|COLWOOD HATLEY DR...|\n",
      "|CA001011860| 48.8333|-123.8333|    177.0|   BC|COPPER CANYON    ...|\n",
      "|CA001011920| 48.5333|-123.3667|     37.0|   BC|CORDOVA BAY      ...|\n",
      "|CA001011922| 48.5167|-123.3667|     26.0|   BC|CORDOVA BAY SOUTH...|\n",
      "+-----------+--------+---------+---------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations_parsed.where( col(\"STATE\") == \"BC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118492"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_parsed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
